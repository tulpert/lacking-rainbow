#!/usr/bin/python3

import os
import re
import sys
import time
import yaml
import json
import random
import datetime
import tempfile

from os import path
from subprocess import check_output

debug                   = True
deletetmpfileonfinish   = False

# Run variables. Edit at your own leisure
runpath                 = '/opt/orchestration'      # Path to where the codebase lives. Usually home directory of the service user
logfilepath             = '/tmp/logfile'            # Your friendly neighborhood log file
logfilepath             = '/var/www/html/schnarf'
runfile                 = runpath + '/.orchrun'     # This is used to keep track of when the last git pull took place
cloudformationregex     = 'cloudformation'          # A regex. If file contains this string, then expect cloudformation content and deploy directly
goodinstancetypes       = ['t2.micro', 'db.t2.micro']
environmentkeys         = ['prod', 'dev', 'test']
# default_sleep           = 5                         # Default #seconds between checking if Cloudformation stack creation is completed
# rds_sleep               = 60                        # #seconds between checking if Cloudformation stack RDS creation is completed

# Functional variables. Edit at your own risk
fullpath                = path.abspath(__file__)
shortpath               = (__file__)
gitbasedirectory        = re.sub("/$", '', fullpath.replace(shortpath, ''))    # Retrieve the git branch base directory
gitbranchname           = re.sub("^.*/", '', gitbasedirectory)
commithistoryfile       = str(gitbasedirectory) + '/.git/.commithistory'
metafiles               = ['meta.yaml', 'meta.yml', 'meta.json']
creationkeystring       = 'StackCreationPath'
region                  = 'eu-west-2'
envyamlkey              = 'env'
runid                   = str(random.randint(100000,999999))
loop_seconds            = 1800
timer_logcount          = 10                            # How many seconds between logging when waiting for new stackbuild
templatedir             = "/opt/orchestration/templates/"
filefilter              = '[a-zA-Z0-9]+'
gitlogformat            = 'Commit [%ci] %H %b by %cn <%ce>: %s'
timedeltadays           = '1'                      # If the lastruntime is missing, when should we default to as last run time?
currenttimeformat       = '%Y-%m-%d %H:%M:%S'

def main():
    # We are currently working in branch $branchname
    logAndInform ("Starting run id ["+runid+"]. Working in: " + gitbranchname)

    # Find out when this script ran last and log current timestamp in order to create logs on changes to repository
    t               = datetime.datetime.now()
    currenttime     = str(t.strftime(currenttimeformat))
    lastruntime     = (t - datetime.timedelta(days=int(timedeltadays))).strftime(currenttimeformat)
    if os.path.isfile(runfile):
        try:
            f = open(runfile, "r")
            lastruntime = str(f.read().split("\n")[0])
            logAndInform("Found last runtime [" + str(lastruntime) + "]", msgtype="DEBUG")
            f.close()
        except Exception as e:
            logAndInform("Could not read runfile. Message: " + str(e), msgtype="ERROR")
    else:
        logAndInform("Did not read runfile. Maybe this was the first run?", msgtype="INFO")
    # Log the current time so future runs can use the data to create logs on changes to repository
    try:
        f = open(runfile, 'w')
        f.write(str(currenttime))
        f.close()
    except Exception as e:
        logAndInform("Could not update runfile. Coderef 399. Message: " + str(e))
    # git log --since="2018-08-11 09:58:10" --format='Commit %H %b by %cn <%ce>: %s' 


    # logAndInform ("ENVIRON: " + str(os.environ), msgtype="DEBUG")

    # Extrapolate which commits have been published based on timestamp since last run
    gitlogdict = ['git', 'log', '--since="'+lastruntime+'"', '--format="'+gitlogformat+'"']
    gitlog = check_output(gitlogdict)
    logAndInform("Running GIT LOG command: " + str(gitlogdict), msgtype="DEBUG")
    logAndInform("Working on following git commits: \n" + str(gitlog.decode().strip()), msgtype="INFO", teams=True)

    myconfig = dict()

    changes = check_output(['git', 'diff', '--name-status', 'HEAD@{1}'])
    logAndInform("GitDiff: \n" + str(changes.decode()), msgtype="INFO")
    change_array = str(changes.decode()).split("\n")
    for i in change_array:
        # Run through the status of the files which have been updated
        change = str(i)
        if re.match('^[A-Z]\d*\s+', change):
            logAndInform("FILE BEING CHANGED: " + i, msgtype="DEBUG")
            operator        = change[0]                                     # The operator is A (Added), M (Modified), D (Deleted) or R (Renamed)
            file_changed    = re.sub('^\s*[A-Z]\d*\s*', '', change)         # The file changed (full path from basedir). i.e. app/app-component/cloudformation.yaml
            base_change     = re.sub('\/.*$', '', file_changed)             # The base of the change. Either a file (because it was in basedir) or the directory name. i.e. app
            content_change  = re.sub('.*[/]', '', file_changed)             # The content changed. This will be the config file in an application component. i.e. 
            application     = re.sub('\/.*$', '', base_change)              # The application is the highest directory name. Can be similar to base_change sometimes
            application = re.sub('\.y[a]{0,1}ml|\.json', '', application)   # If the application is in base folder it might contain the file suffix. Remove it!

            if debug:
                logAndInform('Content     -> ' + content_change, msgtype="DEBUG")
                logAndInform('Base_change -> ' + base_change, msgtype="DEBUG")
                logAndInform('Application -> ' + application, msgtype="DEBUG")
    
            # Check the operator. 
            # M = Modified -> Will require reprovisioning
            # A = Added    -> Will require a new stack
            # D = Deleted  -> Will require removal of stack
            # Establish what needs to be done. 
            # * Is it a new stack?
            # * Is it an existing stack that needs to be changed?
            # * Is it single component?
            # * What type of deployment?
            if content_change.lower() in metafiles:
                if operator == 'A':
                    logAndInform("Detected ADD event: [" + file_changed + "]", msgtype="DEBUG")
                elif operator == 'D':
                    logAndInform("Detected DELETE event: [" + file_changed + "]", msgtype="DEBUG")
                elif operator == 'R':
                    logAndInform("Detected RENAME event: [" + file_changed + "]", msgtype="DEBUG")
                elif operator == 'M':
                    logAndInform("Detected MODIFY event: [" + file_changed + "]", msgtype="DEBUG")
                logAndInform("We do not invoke automation when adding/editing/removing meta files. Yet... Coderef 50", msgtype="DEBUG")
            else:
                if operator == 'R':
                    splitthis = file_changed.split("\t")
                else:
                    splitthis = [file_changed]

                counter = 0
                while counter <= 1:
                    if len(splitthis) > 1:
                        if counter == 0:
                            operator = 'A'
                            file_changed = splitthis[1]
                        elif counter == 1:
                            operator = 'D'
                            file_changed = splitthis[0]
                        counter = counter +1
                    else:
                        counter = 9999 # <--- This will run only once, then break out of while loop
                    # Which application component is being changed?
                    app_component   = ''
                    if re.search('\/', file_changed):
                        app_component   = file_changed.split("/")[1]           
                    app_component   = re.sub('\.y[a]{0,1}ml$|\.json$', '', app_component)
                    app_component   = re.sub('[-_]*'+cloudformationregex+'[-_]*', '', app_component)
                    if len(file_changed.split("/")) >= 3:
                        sub_component   = str('-'.join(file_changed.split("/")[2:]))
                        sub_component   = re.sub('\.y[a]{0,1}ml$|\.json$', '', sub_component)
                        sub_component   = re.sub('[-_]*'+cloudformationregex+'[-_]*', '', sub_component)
                        sub_component   = sub_component + str('-')
                    else:
                        sub_component   = ""
                    logAndInform('App-Componenet -> ' + app_component, msgtype="DEBUG")
                    logAndInform('Sub-Componenet -> ' + sub_component, msgtype="DEBUG")
                    t               = datetime.datetime.now()
                    datestring      = str(t.strftime('%Y%d%m-%s'))
                    stackname       = gitbranchname + "-" + application + '-' + app_component + '-' + sub_component + datestring + '-' + runid
                    # Stackname must must satisfy regular expression pattern: [a-zA-Z][-a-zA-Z0-9]*
                    stackname       = re.sub('_', '', stackname)
    
                    # if base_change == content_change:
                    #     # The file changed lives in the root directory. I don't think we need to do anything.
                    # else:
                    logAndInform('Working on: Application['+application+']['+app_component+']')

                    # Check the config file and do the appropriate actions
                    if re.search('^' + filefilter  + '\.y[a]{0,1}ml$', content_change):
                        logAndInform('Non-Cloudformation Config file detected. Parsing [' + file_changed + ']')
                        if operator == 'A':
                             tmp = doAddCloudformationFromConfig(file_changed, gitbranchname, stackname, region)
                        elif operator == 'D':
                            doDeleteCloudformationFromConfig(file_changed, gitbranchname, stackname, region)
                        elif operator == 'M':
                            doModifyCloudformationFromConfig(file_changed, gitbranchname, stackname, region)
                        elif operator == 'R':
                            splitthis = file_changed.split("\t") 
                            from_file = splitthis[0]
                            to_file   = splitthis[1]
                            logAndInform("Detected RENAME event: [" + file_changed + "]")
                            logAndInform("  -> RENAME OF NON-CLOUDFORMATION FILE IS NOT IMPLEMENTED YET 54 <- ", msgtype="WARNING")
                            logAndInform("  fromfile  : " + from_file, msgtype="WARNING")
                            logAndInform("  tofile    : " + to_file, msgtype="WARNING")
                            logAndInform("  gitbname  : " + gitbranchname, msgtype="WARNING")
                            logAndInform("  stackname : " + stackname, msgtype="WARNING")
                            logAndInform("  region    : " + region, msgtype="WARNING")
                            logAndInform("  piss      : " + str(splitthis), msgtype="WARNING")
                            tmp = doAddCloudformationFromConfig(to_file, gitbranchname, stackname, region)
                            doDeleteCloudformationFromConfig(from_file, gitbranchname, stackname, region)
                        else:
                            logAndInform("Detected Unknown event. Cannot continue. Error 42. ["+file_changed+"]", msgtype="ERROR")
                        
                    elif re.search(cloudformationregex, content_change) and re.search('\.y[a]{0,1}ml$|\.json$', content_change):
                        # We've detected a fully fledged cloudformation file.
                        logAndInform('Cloudformation file detected. Parsing [' + file_changed + ']')
                        #
                        # Future Task: Workflow can be edited to utilize queue service (i.e AWS SQS) 
                        #
                        if operator == 'A':
                            doAddCloudformation(file_changed, gitbranchname, stackname, region)
                        elif operator == 'D':
                            doDeleteCloudformation(file_changed, gitbranchname, stackname, region)
                        elif operator == 'R':
                            logAndInform("Detected RENAME event: [" + file_changed + "]")
                            logAndInform("  -> RENAME IS NOT IMPLEMENTED YET 66 <- ", msgtype="WARNING")
                            # --> print ("There has been some renaming, but nothing else has changed. 
                            # Check if new config files not exist and perform ADD. If not, see if we need to update any tags. 
                            # If not, then ignore.")
                        elif operator == 'M':
                            # Decide to either update the old stack or replace it
                            # doUpdateCloudformation(file_changed, gitbranchname, stackname, region)
                            doReplaceCloudformation(file_changed, gitbranchname, stackname, region)
                        else:
                            logAndInform("Detected Unknown event. Cannot continue. Error 42. ["+file_changed+"]", msgtype="ERROR")
                    else:
                        logAndInform("Cannot recognize file type on [" + content_change + "]. Will ignore", msgtype="INFO")

            logAndInform("----- Finished with [" + file_changed + "] -----", msgtype="DEBUG")

        else:
            if not re.match('^\s*$', change):
                logAndInform("Found no operator!. Error 16", msgtype="ERROR")
    logAndInform("Finished run id ["+runid+"]!")
    logAndInform(" -----  END ----- ")
    


def logAndInform(message, nologfile=False, email=False, teams=False, logfile=logfilepath, msgtype='INFO'):
    if not msgtype.lower() == "debug" or debug:
        t = datetime.datetime.now() - datetime.timedelta(seconds=4)             # Each git pull takes on average x seconds. This is a guestimate
        datestring = str(t.strftime('%m %b %Y %H:%M:%S (UTC?)'))
        my_message = datestring + ' ['+str(msgtype).upper()+'] ['+runid+'] ' + str(message) + "\n"
        if logfile and not nologfile:
            try:
                w=open(logfilepath, 'a')
                w.write(my_message)
                w.close()
            except Exception as e:
                print (datestring + " [ERROR] ["+runid+"] Could not write message to logfile! Error 1144. Message: " + str(e))
        if teams:
            logAndInform("=========>  TODO: Implement push to teams. Coderef 443", msgtype="INFO")
        if email:
            logAndInform("=========>  TODO: Implement push to email. Coderef 25", msgtype="INFO")
    
def validateCloudformation(cffile):
    # This function will read through the cloudformation file and verify
    # that all elements exists and are within compliance and naming standards
    # I.e.: Tags, EasyRisk IDs, Costcenter IDs, Naming convention etc...
    # ---> Push to external lint script
    # If all good, push to account
    #
    # Tests:
    # * Name tag exists
    # Is valid YAML - OK
    # Is valid JSON - Written code. Must be tested!
    returnvalue = True
    _tmp = getDictFromFile(cffile)
    if isinstance(_tmp, dict):
        if "Resources" in _tmp.keys():
            for resource in _tmp["Resources"].keys():
                if not re.match('^[A-Za-z0-9]*$', str(resource)):
                    logAndInform("Resource name must be alphanumeric in Cloudformation. Resource [" + str(resource) + "] is rejected", msgtype="FAILURE")
                    return False
                if 'Type' in _tmp["Resources"][resource].keys():
                    if _tmp['Resources'][resource]['Type'] == 'AWS::RDS::Instance':
                        _instanceTypeString = 'InstanceType'
                    elif _tmp['Resources'][resource]['Type'] == 'AWS::RDS::DBInstance':
                        _instanceTypeString = 'DBInstanceClass'
                    else:
                        returnvalue = True
                        _instanceTypeString = False
                        logAndInform("Validation function has no logic to validate Resources of Type [" + str(_tmp['Resources'][resource]['Type']) + "]. Will approve, but it might fail... Coderef 1712") 
                else:
                    returnvalue = False
                    logAndInform("Validation could not locate Type declaration in Cloudformation. Coderef 1711")
                if _instanceTypeString:
                    r = _tmp["Resources"][resource]["Properties"]
                    if str(_instanceTypeString) in r.keys():
                        if not str(r[str(_instanceTypeString)]).lower() in goodinstancetypes:
                            returnvalue = False
                            logAndInform("Tried to provision unapproved instance type: " + r[str(_instanceTypeString)], msgtype="FAILURE")
                    else:
                        returnvalue = False
                        logAndInform("Missing expected Instance Type of [" + str(_instanceTypeString) + "] in CloudFormation file. Coderef 1713")
        else:
            logAndInform("Missing `Resources` key in cloudformation", msgtype="FAILURE")
    else:
        returnvalue = False
        logAndInform("Validation could not load the contents of cloudformation. Coderef 1710")
    logAndInform("Validation of Cloudformation is still WIP and in Beta! Check log if status is False or Rejected. Current value is: " + str(returnvalue), msgtype="WARNING")
    return returnvalue

def doAddCloudformation(cloudformationfile, account, name, region):  
    newdeploy = '{"message": "Will not create cloudformation file. Coderef 1770."}'
    # Only Create if the cloudformationfile actually ends with yaml, yml or json
    if re.search('\.y[a]{0,1}ml$|\.json$', cloudformationfile):
        if validateCloudformation(cloudformationfile):        # Checking if cloudformationfile has valid formatting, namingstandard and compliant
            logAndInform("Detected ADD event: [" + cloudformationfile + "]")
            logAndInform("Creating new Cloudformation stack: [" + cloudformationfile + "] with name [" + name + "]")
            try:
                newdeploy = check_output(['aws', '--profile', account, 'cloudformation', 'create-stack', '--stack-name', name, '--tags', 'Key="'+creationkeystring+'",Value="'+ str(account) + ':' + cloudformationfile +'"',  '--region', region, '--template-body', 'file://'+cloudformationfile])
            except Exception as e:
                logAndInform("Something was caught in ERROR. Coderef 1771. Message: " + str(e), msgtype="ERROR")
                newdeploy = '{"Message": "I dont think AWS liked this cloudformation file..."}'.encode()
            newdeployoutput = str(newdeploy.decode())
            logAndInform(str(newdeploy.decode()), msgtype="DEBUG")
            for _line in newdeployoutput.split("\n"):
                logAndInform(" # " + _line, msgtype="DEBUG")
    return newdeploy

def doUpdateCloudformation(cloudformationfile: str, account: str; name: str, region: str) -> dict:
    logAndInform("Detected Update Cloudformation event: [" + cloudformationfile + "]")
    # Return the latest created and valid cloudformation stack for this name
    # aws cloudformation describe-stacks --query "Stacks[].{CreationTime: CreationTime, Status: StackStatus, Name: StackName} | reverse(sort_by(@, &CreationTime))[:1]"
    # aws cloudformation describe-stacks --query "Stacks[?StackStatus == 'CREATE_COMPLETE' || StackStatus == 'CREATE_FAILED' ].{CreationTime: CreationTime, Status: StackStatus, Name: StackName} | reverse(sort_by(@, &CreationTime))[:1]"

    searchstack = check_output(['aws', '--profile', account, 'cloudformation', 'describe-stacks', '--region', region, '--query', 'Stacks[?(Tags[?Key == \'StackCreationPath\' && Value == \'' + str(account) + ':' + cloudformationfile + '\'])][StackId]', '--output', 'text'])
    # aws --profile dev cloudformation describe-stacks --region eu-west-2 --query "Stacks[?(Tags[?Key == StackCreationPath && Value == 'dev:*'])][StackId] --output text

def doReplaceCloudformation(cloudformationfile, account, name, region):
    logAndInform("Detected REPLACE Cloudformation event: [" + cloudformationfile + "]")
    # Modification has occured. Do the following:
    # 1. Find the previous version of the cloudfoundation stack (if exists)
    # 2. Create new cloudformation stack
    # 3. Verify that new stack is OK
    # 4. Delete old cloudformation stack
    # Hint: use SQS for this!

    doDeletePreviousStack = False
    
    # 1
    searchstack = check_output(['aws', '--profile', account, 'cloudformation', 'describe-stacks', '--region', region, '--query', 'Stacks[?(Tags[?Key == \'StackCreationPath\' && Value == \'' + str(account) + ':' + cloudformationfile + '\'])][StackId]', '--output', 'text'])
    if debug:
        logAndInform("'aws', '--profile', " + account + ", 'cloudformation', 'describe-stacks', '--region', " + region + ", '--query', " + 'Stacks[?(Tags[?Key == \'StackCreationPath\' && Value == \'' + str(account) + ':' + cloudformationfile + '\'])][StackId]' + ", '--output', 'text' ", msgtype="DEBUG")
    stacksWithSearchTag = str(searchstack.decode()).split("\n")
    newstack = doAddCloudformation(cloudformationfile, account, name, region)
    # TODO: Insert logic here to detect that the new stack is active and working!
    responsarray = json.loads(str(newstack.decode()))
    logAndInform ("Creating new Stack. StackID [" + responsarray["StackId"] + ']. This could take a few minutes depending on your requested deployment. Please wait...')
    
    
    # Loop for a while to see if the new stack comes up OK.
    loop = 0
    timer_counter = 0
    while loop < loop_seconds:
        # Check status of the running stack-create
        create_status = check_output(['aws', '--profile', account, 'cloudformation', 'describe-stacks', '--region', region, '--stack-name', str(responsarray["StackId"]), '--query', 'Stacks[].StackStatus', '--output', 'text' ])
        if "CREATE_IN_PROGRESS" in str(create_status):
            timer_counter = timer_counter + 1
            if timer_counter > timer_logcount:
                logAndInform ("Still waiting for CREATE_COMPLETE on StackId[" + str(responsarray["StackId"]) + "]. Please have patience...")
                timer_counter = 0
            time.sleep(20)
        elif "CREATE_COMPLETE" in str(create_status):
            loop = loop_seconds
            doDeletePreviousStack = True
        else:
            # Message status is other than what we expected. Inform user!
            logAndInform ("Create status mismatch. Expected CREATE_COMPLETE. Got [ " + str(create_status.decode().strip()) + "]", msgtype="ERROR")
            loop = loop_seconds
 
    for stackid in stacksWithSearchTag:
        if not re.search('^\s*$', stackid):
            if doDeletePreviousStack:
                logAndInform("Calling delete on old cloudformation stack [" + str(stackid) + "]")
                doDeleteCloudformation(str(stackid), account, name, region)
            else:
                logAndInform("New stack creation status is [" + str(create_status) + "]. Expected CREATE_COMPLETE. Will not delete old stack.", msgtype="FAILURE") 

def doModifyCloudformationFromConfig(configfile: str, account: str, name: str, region: str):
    doDeletePreviousStack = False
    # Find previous version of cloudfoundation stack (if exists)
    searchstackarray = ['aws', '--profile', account, 'cloudformation', 'describe-stacks', '--region', region, '--query', 'Stacks[?(Tags[?Key == \'StackCreationPath\' && Value == \'' + str(account) + ':' + configfile + '\'])][StackId]', '--output', 'text']
    logAndInform("Running: " + str(' '.join(searchstackarray)), msgtype="DEBUG")
    searchstack = check_output(searchstackarray)
    stacksWithSearchTag = str(searchstack.decode()).split("\n")
    logAndInform("Found: " + str(stacksWithSearchTag), msgtype="DEBUG")
    logAndInform("NOT IMPLEMENTED YET", msgtype="NOT IMPLEMENTED YET") 

    # First, create the new stack
    newstack = doAddCloudformationFromConfig(configfile, account, name, region)
    responsarray = json.loads(str(newstack.decode()))
    if "StackId" in responsarray.keys():
        logAndInform ("Creating new Stack. StackID [" + responsarray["StackId"] + ']. This could take a few minutes depending on your requested deployment. Please wait...')
        logAndInform ("Actually, this will take ZERO time, because this has not been implemented yet. Psyche!! Remember to remove the -999 loop_seconds before testing in real life!", "---> TODO <---")
        loop_seconds = -999   # <---- REMOVE THIS WHEN "MAKE" CODE IS IN PLACE
        # Loop for a while to see if the new stack comes up OK.
        loop = 0
        timer_counter = 0
        while loop < loop_seconds:
            # Check status of the running stack-create
            create_status = check_output(['aws', '--profile', account, 'cloudformation', 'describe-stacks', '--region', region, '--stack-name', str(responsarray["StackId"]), '--query', 'Stacks[].StackStatus', '--output', 'text' ])
            if "CREATE_IN_PROGRESS" in str(create_status):
                timer_counter = timer_counter + 1
                if timer_counter > timer_logcount:
                    logAndInform ("Still waiting for CREATE_COMPLETE on StackId[" + str(responsarray["StackId"]) + "]. Please have patience...")
                    timer_counter = 0
                time.sleep(20)
            elif "CREATE_COMPLETE" in str(create_status):
                doDeletePreviousStack = True
                loop = loop_seconds
            else:
                # Message status is other than what we expected. Inform user!
                logAndInform ("Create status mismatch. Expected CREATE_COMPLETE. Got [ " + str(create_status.decode().strip()) + "]", msgtype="ERROR")
                loop = loop_seconds
    else:
        logAndInform("Creating stack failed. Message: " + str(responsarray), msgtype="ERROR")

    # Finally remove the old Stack(s)
    for stackid in stacksWithSearchTag:
        if not re.search('^\s*$', stackid):
            if doDeletePreviousStack:
                logAndInform("Calling delete on old cloudformation stack [" + str(stackid) + "]")
                doDeleteCloudformation(str(stackid), account, name, region)
            else:
                logAndInform("New stack creation status is [" + str(create_status) + "]. Expected CREATE_COMPLETE. Will not delete old stack.", msgtype="FAILURE") 
        else:
            logAndInform("No existing stack(s) found related to the config file [" + str(configfile) + "]", msgtype="DEBUG")


def doDeleteCloudformation(element, account, name, region):
    logAndInform("Performing DELETE event: [" + element + "]")
    deletestack = False
    if re.search('^arn\:aws\:cloudformation', element):
        # This is a Cloudformation ID. We can delete it directly
        if debug:
            logAndInform("Detected ARN ID [" + str(element) + "]", msgtype="DEBUG")
        stackid = str(element)
        deleteStackIds = [stackid, ""]
    elif re.search('^\s*$', element):
        deleteStackIds = ["", ""]
        do = "nothing"    # The line is empty. This happens when there is a newline at the end of the aws describe json output
    else:
        logAndInform("Detected cloudformation filepath - must do search based on Tags.", msgtype="DEBUG")
        searchstack = check_output(['aws', '--profile', account, 'cloudformation', 'describe-stacks', '--region', region, '--query', 'Stacks[?(Tags[?Key == \'StackCreationPath\' && Value == \'' + str(account) + ':' + element + '\'])][StackId]', '--output', 'text'])
        deleteStackIds = str(searchstack.decode()).split("\n")
        if len(deleteStackIds) <= 1:
            logAndInform("A Stack was not found which relates to [" + element + "]. Cannot delete.", msgtype="WARNING")
    for stackid in deleteStackIds:
        if not re.search('^\s*$', stackid):
            logAndInform("Performing delete of StackId [" + str(stackid) + ']')
            deletestack = check_output(['aws', '--profile', account, 'cloudformation', 'delete-stack', '--region', region, '--stack-name', stackid])
    logAndInform("Deletion of ["+name+"] probably was a success! ReferenceID: "+runid+". Output: " + str(deletestack), msgtype="DEBUG")

def validateConfig(configfile):
    logAndInform("Validation of Config is not fully implemented at this time!!!", msgtype="WARNING")
    return True

def doAddCloudformationFromConfig(configfile: str, account: str, name: str, region: str) -> bytes:
    doAdd = True
    returnstring = '{"Message": "Creating Cloudformation from configfile ['+str(configfile)+'] was not event attempted. Coderef: 1066"}'
    returnvalue = bytes(returnstring.encode())
    logAndInform("Performing doAddCloudformationFromConfig on configfile ["+configfile+"], account ["+account+"], region ["+region+"]", msgtype="DEBUG")
    # Check if the config is valid before proceeding
    if validateConfig(configfile):
        logAndInform(" CREATE config not implemented yet", msgtype="WARNING")
        
        myconfig = dict()
        mypath = ''
        for i in configfile.split('/'):
            metafile = str(mypath + 'meta.yaml')
            if os.path.isfile(metafile):
                metaarray = dict()
                try:
                    with open(metafile, 'r') as stream:
                        metaarray = yaml.load(stream)
                        # Extract the environment specific variables
                        tmparray = dict()
                        for _key in metaarray.keys():
                            if envyamlkey in metaarray.keys():
                                if str(account) in metaarray[envyamlkey].keys():
                                    for _subkey in metaarray[envyamlkey][str(account)]:
                                        tmparray[_subkey] = metaarray[envyamlkey][str(account)][_subkey]
                            else:
                                tmparray[_key] = metaarray[_key] 
                        metaarray = tmparray 
                except Exception as e:
                    logAndInform("Could not load meta file [" + str(metafile) + "]. Error ref 889. Message: " + str(e), msgtype="ERROR")
                if (isinstance(metaarray, dict)):
                    myconfig = dict(myconfig, **metaarray)      # Add two dicts together (The new overwrites the old of two keys are the same!)
                else:
                    logAndInform("File exists, but does not contain valid YAML code. Cannot parse content of ["+str(metafile)+"]", msgtype="DEBUG")
                    doAdd = False
            mypath = mypath + i + '/'
        logAndInform("Contents of META : " + str(myconfig), msgtype="DEBUG")
        metaarray = ""
        try:
            with open(configfile, 'r') as stream:
                metaarray = yaml.load(stream)
        except Exception as e:
            logAndInform("Yaml config file ["+str(configfile)+"] is broken or this is not a Yaml file! Coderef 1003. Message: " + str(e), msgtype="ERROR")
            doAdd = False

        # Add the configfile yaml content to the myconfig Dict
        if (isinstance(metaarray, dict)):
            myconfig = dict(myconfig, **metaarray)
        else:
            logAndInform("File exists, but does not contain valid YAML code. Cannot parse content of ["+str(configfile)+"]", msgtype="DEBUG")
            doAdd = False

        if doAdd:

            # TODO: Some logic to merge meta.yaml TAGS with myconfig.
            if "Tags" in myconfig.keys():
                tags = myconfig["Tags"]
                logAndInform("Found these META.yaml tags to include in the config: " + str(tags), msgtype="DEBUG")
                logAndInform("Adding META tags is still WIP. Going to bed now!", msgtype="DEBUG")

            

            logAndInform("Contents of MYCONFIG after merge : " + str(myconfig), msgtype="DEBUG")

            newtempfile = tempfile.mkstemp(prefix="orch_runid_" + str(runid) + "_")
            
            try:
                newtempfilename = str(newtempfile[1])
                logAndInform("TEMPFILE     -> " + newtempfilename, msgtype="DEBUG")
                templatefile = open(newtempfilename, "w")
                templatefile.write(str(yaml.dump(myconfig)))
                templatefile.close()
                if deletetmpfileonfinish:
                    os.unlink(newtempfilename)
                    logAndInform("Deleting TMP file ["+str(newtempfilename)+"]", msgtype="DEBUG")
            except Exception as e:
                logAndInform("Could not create temp config file. Coderef 766. Message: " + str(e), msgtype="ERROR")

            # Here is where we call external YAML Generator. I.e. ansible, terraform etc
            if os.path.isfile(newtempfilename):
                mycmd = ['make', 'filedeploy', "env="+str(account), "file="+newtempfilename ] # '', 'on', 'tmpfile', newtempfilename]
                try:
                    logAndInform("RUN: " + str(' '.join(mycmd)), msgtype="COMMAND")
                    returnvalue = bytes('{"Message": "This will be some output from MAKE command when implemented"}'.encode())
                except Exception as e:
                    logAndInform("Code ref 942. Message: " + str(e), msgtype="ERROR")
    return returnvalue
    
def doDeleteCloudformationFromConfig(configfile, account, name, region):
    logAndInform("Performing doDeleteCloudformationFromConfig on configfile ["+configfile+"], account ["+account+"], region ["+region+"]", msgtype="DEBUG")
    doDeleteCloudformation(configfile, account, name, region)
    

def getDictFromFile(configfile: str) -> dict:
    # This function will return a dict from a yaml or json file
    if os.path.isfile(configfile):
        try:
            logAndInform("Yay! Were using the new getDictFromFile function!", msgtype="DEBUG")
            with open(configfile, 'r') as stream:
                if re.match('^\.y[a]{0,1}ml$', configfile):
                    _mydict = yaml.load(stream)
                elif re.match('^.*\.json$', configfile):
                    _mydict = json.load(stream)
                else:
                    return False
        except Exception as e:
            logAndInform("Could not transform file to dict. Error: " + str(e), msgtype="FAILURE")
    else:
        return False
    return _mydict

main()
